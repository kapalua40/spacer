{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb746d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, logging, os, time, random\n",
    "from optparse import OptionParser\n",
    "from bs4 import BeautifulSoup\n",
    "import config\n",
    "import user_agent as ua\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "formd = ' %(asctime)s - %(levelname)s - %(message)s' \n",
    "if config.debug == True:\n",
    "    logging.basicConfig(level=logging.DEBUG, format = formd)\n",
    "else:\n",
    "    logging.basicConfig(level=logging.INFO, format = formd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1a06bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.debug('Начало')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rolled-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Готовые ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reflected-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def debug(text):\n",
    "    logging.debug(text)\n",
    "# \n",
    "def info(text):\n",
    "    logging.info(text)\n",
    "# \n",
    "def error(text):\n",
    "    logging.error(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "robust-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбрасывает сообщение об ошибке на диск файлом\n",
    "def error_dump(text):\n",
    "    # \n",
    "    dt = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "    name = 'ERRORS.txt'\n",
    "    with open(name, 'a') as f:\n",
    "        f.write(f\"{dt}: {text}\\n\\n\")\n",
    "        info(f\"Сброшено на диск, в файл {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "political-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем рандомный user-agent\n",
    "def random_ua(k=1):\n",
    "    return random.choices(list(ua.ua_pct['ua'].values()), list(ua.ua_pct['pct'].values()), k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "signal-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получить ссылку автовхода\n",
    "def get_autolink(filename):\n",
    "    \n",
    "    arr = {}\n",
    "    links = 0\n",
    "    with open(filename, 'r') as f:\n",
    "        links = f.readlines()\n",
    "    \n",
    "    for link in links:\n",
    "        db = link.strip().split(';')\n",
    "        arr[db[0]] = db[1]\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c162e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем сессию\n",
    "def get_session(url_login):\n",
    "    # Берём случайный user-agent\n",
    "    global headers\n",
    "    global stat\n",
    "    headers = { 'User-Agent': random_ua()[0] }\n",
    "    i = 0\n",
    "    \n",
    "    debug(headers)\n",
    "    \n",
    "    while i < config.limit:\n",
    "        try:\n",
    "            session = requests.Session()\n",
    "            r = session.get(url_login, headers = headers)\n",
    "            r.raise_for_status()\n",
    "            session.headers.update({'Referer': url_login})\n",
    "\n",
    "            stat['count_session'] += 1\n",
    "            debug(f\"headers: {headers}/referer: {url_login}\")\n",
    "\n",
    "            return session\n",
    "        except requests.exceptions.BaseHTTPError as e:\n",
    "            error(f\"Error in get_session()\")\n",
    "            error_dump(e)\n",
    "            stat['count_disconnect'] += 1\n",
    "            i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "processed-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# НЕ готово!\n",
    "# Поучает статус со страницы пользователя\n",
    "def get_status_from_userpage(text_page):\n",
    "    ###\n",
    "    # \n",
    "    bs = BeautifulSoup(text_page, 'html.parser')\n",
    "    t = bs.select(config.class_status_page)\n",
    "\n",
    "    if len(t) > 0:\n",
    "        return t[0].text\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-minority",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-deadline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quality-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Достаёт анкету страницы юзера\n",
    "def get_anketa_from_userpage(session, nick):\n",
    "    ###\n",
    "    url = f\"{config.scheme}://{config.base_url}/anketa/index/{nick}/\"\n",
    "    res = aget(session, url)\n",
    "\n",
    "    return res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "precious-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Готово!\n",
    "# Получает страницу с аватаркой\n",
    "def get_avatar_page(text):\n",
    "    ###\n",
    "    # аватарка\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    t = bs.select(config.class_avatar_page )\n",
    "    b = t[0].select('a') if len(t) else ''\n",
    "    href = b[0].attrs['href'] if len(b) > 0 else ''\n",
    "    \n",
    "    #print(href)\n",
    "    res = aget(session, href)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25844508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Готово!\n",
    "# Получаем следующую страницу в папке\n",
    "def get_next_page(text):\n",
    "    b = BeautifulSoup(text, 'html.parser')\n",
    "    arr = b.select(config.class_next_page)\n",
    "    \n",
    "    if len(arr) > 0:\n",
    "        return arr[0].attrs['href']\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cellular-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Получаем следующую страницу в папке - без класса\n",
    "def get_next_page2(text):\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    rs = bs.select('a')\n",
    "\n",
    "    ret = 0\n",
    "    for rrr in rs:\n",
    "        if rrr.text.lower().__contains__(config.text_next.lower()):\n",
    "            ret = rrr.attrs['href']\n",
    "            break\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "finite-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачиваем аватар, его превьюхи и сохраняем\n",
    "def get_avatar(session, text, stor):\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    # Получаем ссылку на страницу с аватаркой и ссылку на маленькое превью\n",
    "    ff = bs.select(config.class_avatar[0])\n",
    "    ff2 = bs.select(config.class_avatar[1])\n",
    "\n",
    "    #Если аватарка есть\n",
    "    if len(ff) > 0:\n",
    "        url_ava_page = ff[0].attrs['href']\n",
    "        # Скачиваем страницу с аватаркой\n",
    "        r2 = aget(session, url_ava_page)\n",
    "\n",
    "        # Получаем ссылку на файл аватара и дату публикации его на сервере\n",
    "        url_ava = get_file_url(r2.text, 'pictures')\n",
    "        dt_published = get_datePublished(r2.text)\n",
    "        \n",
    "        # Скачиваем файл аватара\n",
    "        if len(url_ava) > 0:\n",
    "            fn = os.path.basename(url_ava[0])\n",
    "            save_file(f\"{stor}{os.sep}{fn}\", session, url_ava[0], dt_published)\n",
    "        # Получаем превьюшки 600 и 800\n",
    "        preview_files = get_prev_pic(r2.text)\n",
    "        # Скачиваем их\n",
    "        for pf in preview_files:\n",
    "            fn = os.path.basename(pf)\n",
    "            save_file(f\"{stor}{os.sep}{fn}\", session, pf, dt_published)\n",
    "\n",
    "    # Если есть маленькое превью\n",
    "    if len(ff2) > 0:\n",
    "        preview_ava = ff2[0].attrs['data-s']\n",
    "        fn = os.path.basename(preview_ava)\n",
    "        save_file(f\"{stor}{os.sep}{fn}\", session, preview_ava, time='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "complimentary-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Готово!\n",
    "### Получаем закладки с одной страницы\n",
    "def get_bookmarks_page(session, url, file):\n",
    "    r = aget(session, url)\n",
    "    bs = BeautifulSoup(r.text, 'html.parser')\n",
    "    t = bs.select(config.class_bookmarks)\n",
    "\n",
    "    with open(file, 'a') as f:\n",
    "        for bk in t:\n",
    "            print(f\"{bk.get_text()}; {bk.attrs['href']}\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-float",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-vampire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-bidding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-begin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "silver-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Готово!\n",
    "# Получает закладки со всех страниц\n",
    "def get_bookmarks_all(session, file):\n",
    "\n",
    "    url = f'{config.scheme}://{config.base_url}/bookmarks/'\n",
    "\n",
    "    while url != 0:\n",
    "        get_bookmarks_page(session, url, file)\n",
    "        \n",
    "        res = aget(session, url)\n",
    "        url = get_next_page2( res.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "binding-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Готово!\n",
    "# Получает ник пользователя под которым сидим на сайте\n",
    "def get_nick(session):\n",
    "    res = aget(session, f\"{config.scheme}://{config.base_url}/mysite/\")\n",
    "    bs = BeautifulSoup(res.text, 'html.parser')\n",
    "    t = bs.select(config.class_nickname)\n",
    "\n",
    "    return t[0].text.strip() if len(t) > 0 else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-weapon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "renewable-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Обёртка над get для удобного перехвата исключений и обработки\n",
    "def aget(session,url):\n",
    "    ###\n",
    "    i = 0\n",
    "    time_sleep = config.time_sleep\n",
    "    response = 0\n",
    "    global stat\n",
    "    \n",
    "    debug(headers)\n",
    "    \n",
    "    while i < config.limit:\n",
    "        try:\n",
    "            response = session.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            if response.status_code == requests.status_codes.codes.OK:\n",
    "                break\n",
    "            elif response.status_code == requests.status_codes.codes.forbidden:\n",
    "                error(f\"Forbidden, response.status_code: {response.status_code}\")\n",
    "                break\n",
    "            else:\n",
    "                error(f\"response.status_code: {response.status_code}\")\n",
    "                error(f\"Ждём {time_sleep} секунд и пробуем снова (#{i+1}/{config.limit})\")\n",
    "                i += 1\n",
    "                \n",
    "                session.close()\n",
    "                time.sleep(time_sleep)\n",
    "                session = get_session(url_login)\n",
    "                stat['count_reconnect'] += 1\n",
    "                debug('Новая сессия')\n",
    "                \n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            if str(e).__contains__('Max retries exceeded'):\n",
    "                error_dump(str(e))\n",
    "                error(f\"Ошибка {str(e)}\\nЖдём {time_sleep} секунд и пробуем снова (#{i+1}/{config.limit})\")\n",
    "                time.sleep(time_sleep)\n",
    "                raise BaseException(-1)\n",
    "            else:\n",
    "                error(f\"Ошибка {str(e)}\\nЖдём {time_sleep} секунд и пробуем снова (#{i+1}/{config.limit})\")\n",
    "                error_dump(str(e))\n",
    "                i += 1\n",
    "                stat['count_disconnect'] += 1\n",
    "                session.close()\n",
    "                time.sleep(time_sleep)\n",
    "                session = get_session(url_login)\n",
    "                stat['count_reconnect'] += 1\n",
    "                debug('Новая сессия')\n",
    "            \n",
    "\n",
    "        except requests.exceptions.BaseHTTPError as e:\n",
    "            stat['count_disconnect'] += 1\n",
    "            error(f\"Ошибка. Скинул сообщение на диск\")\n",
    "            error_dump(e)\n",
    "        except Exception as e:\n",
    "            stat['count_disconnect'] += 1\n",
    "            i += 1\n",
    "            error(f\"Общая ошибка = {str(e)}\")\n",
    "\n",
    "    \n",
    "    return response\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorporated-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Готово!\n",
    "### Берёт файл логинами юзеров и отдаёт их список\n",
    "def get_users(file_users):\n",
    "    ###\n",
    "    li = 0\n",
    "    with open(file_users, 'r') as f:\n",
    "        li= f.readlines()\n",
    "\n",
    "    users = []\n",
    "    if type(li) == list:\n",
    "        for user in li:\n",
    "            users.append(user.strip())\n",
    "    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "executed-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "conventional-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "### По нику и указанному разделу формирует ссылку\n",
    "def get_url(nick, section):\n",
    "    \n",
    "    if section == 'guestbook':\n",
    "        return f'{config.scheme}://{config.base_url}/guestbook/index/{nick}/'\n",
    "    elif section == 'bookmarks':\n",
    "        return f'{config.scheme}://{config.base_url}/bookmarks/'\n",
    "    elif section == 'pictures' or section == 'files':\n",
    "        return f'{config.scheme}://{config.base_url}/{part}/user/{user}/list/-/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "disabled-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ищет страницы с файлами\n",
    "def get_file_page(text, part):\n",
    "    ####\n",
    "    pages = []\n",
    "    #f_page.attrs['href'])\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    if part == 'pictures':\n",
    "        pages = [c.attrs['href'] for c in bs.select(config.class_pictures['page'])]\n",
    "    elif part == 'pic_top':\n",
    "        pages = [c.attrs['href'] for c in bs.select(config.class_pic_top['page'])]\n",
    "    elif part == 'music':\n",
    "        pages = [c.attrs['href'] for c in bs.select(config.class_music['page'])]\n",
    "    elif part == 'video':\n",
    "        pages = [c.attrs['href'] for c in bs.select(config.class_video['page'])]\n",
    "    elif part == 'files':\n",
    "        pages = [c.attrs['href'] for c in bs.select(config.class_files['page'])]\n",
    "        \n",
    "    return pages\n",
    "\n",
    "# Ищет ссылки на файлы и картинки\n",
    "def get_file_url(text, part):\n",
    "    ####\n",
    "    files = []\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    if part == 'pictures':\n",
    "        files = [c.attrs['href'] for c in bs.select(config.class_pictures['file'])]\n",
    "        if len(files) == 0:\n",
    "            files = [el.attrs['href'] for el in bs.select('a[class=\"gview_link\"][href][g]')]\n",
    "\n",
    "    elif part == 'music':\n",
    "        files = [c.attrs['href'] for c in bs.select(config.class_music['file'])]\n",
    "    elif part == 'video':\n",
    "        files = [c.attrs['href'] for c in bs.select(config.class_video['file'])]\n",
    "    elif part == 'files':\n",
    "        files = [c.attrs['href'] for c in bs.select(config.class_files['file'])]\n",
    "    \n",
    "    return files\n",
    "\n",
    "# Ищет ссылки на папки\n",
    "def get_dir_page(text, part):\n",
    "    ####\n",
    "    dirs = []\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    if part == 'pictures':\n",
    "        dirs = [(c.text.strip().replace(os.sep, '_'), c.attrs['href']) for c in bs.select(config.class_pictures['dir'])]\n",
    "    elif part == 'music':\n",
    "        dirs = [(c.text.strip().replace(os.sep, '_'), c.attrs['href']) for c in bs.select(config.class_music['dir'])]\n",
    "    elif part == 'video':\n",
    "        dirs = [(c.text.strip().replace(os.sep, '_'), c.attrs['href']) for c in bs.select(config.class_video['dir'])]\n",
    "    elif part == 'files':\n",
    "        dirs = [(c.text.strip().replace(os.sep, '_'), c.attrs['href']) for c in bs.select(config.class_files['dir'])]\n",
    "    \n",
    "    return dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "respiratory-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def guestbook2(session, url, file):\n",
    "    r = aget(session, url)\n",
    "\n",
    "    while url != 0:\n",
    "\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        t = bs.select(class_guestbook['comment'])\n",
    "\n",
    "        for dd1 in t:    \n",
    "            text = dd1.select('span[itemprop~=\"text\"]')\n",
    "            text = str(text[0]) if len(text) > 0 else str(text)\n",
    "\n",
    "            dt = dd1.select('span[class=\"comment_date\"]')\n",
    "            date = dt[0].text.strip() if len(dt) > 0 else '???'\n",
    "\n",
    "            name = dd1.select('b[itemprop=\"name\"]')\n",
    "            name = name[0].text if len(name) > 0 else '???'\n",
    "\n",
    "            print(f\"{name}\\n{date}\\n{text}\\n\")\n",
    "\n",
    "        url = get_next_page2( r.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "postal-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_guestbook = { 'text': 'div[itemprop=\"text\"]', \n",
    "                   'comment': 'div[class=\"comm shdw text cf\"]',\n",
    "                  'date': 'a[class=\"inl-link\"]',\n",
    "                   'text2': 'span[itemprop=\"text\"]'}\n",
    "\n",
    "# TODO\n",
    "### Вытаскиваем всё из гостевой\n",
    "def guestbook(session, url, file):\n",
    "    # гостевая\n",
    "    while url != 0:\n",
    "        #div itemprop=\"text\"\n",
    "        res = aget(session, url)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')\n",
    "        t = bs.select(class_guestbook['text'])\n",
    "\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')\n",
    "        a = bs.select(class_guestbook['2'])\n",
    "\n",
    "        for cc in a:\n",
    "            ### Дата коммента\n",
    "            pre_dt = cc.select(class_guestbook['date'])\n",
    "            dt = pre_dt[0].text if len(pre_dt) > 0 else ''\n",
    "\n",
    "            ### Коммент\n",
    "            pre_cc = cc.select(class_guestbook['3'])\n",
    "            text = pre_cc[0].text if len(pre_cc) else ''\n",
    "\n",
    "            with open(file, 'a') as f:\n",
    "                print(f\"{dt};{text}\", file=f)\n",
    "            \n",
    "        url = get_next_page2( res.text )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "affecting-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Принимает страницу с аватаром, отдает ссылку на сам аватар\n",
    "def get_avatar_url(text):\n",
    "    bs = BeautifulSoup(res.text, 'html.parser')\n",
    "    tag = bs.select('meta[property=\"og:image\"]')\n",
    "    return tag[0].attrs['content'] if len(tag) > 0 else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mounted-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_class(text, class_):\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    t = bs.select('a[class=\"gview_link\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81df1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем превьюшки 600 и 800\n",
    "def get_prev_pic(text):\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    cl1 = 'a[class~=\"gview_link\"]'\n",
    "    t = bs.select(cl1)\n",
    "   \n",
    "    if len(t) == 0:\n",
    "        error('800-600 error')\n",
    "        rr = bs.select('img[class=\"preview\"]')\n",
    "        \n",
    "        if len(rr)>0:\n",
    "            return (rr[0].attrs['src'])\n",
    "        else:\n",
    "            return ()\n",
    "    else:\n",
    "        g = t[0].attrs['g']\n",
    "        g2 = g.split('||')[-3]\n",
    "\n",
    "    # Фотки с размером 600 и 800, без подписи\n",
    "    url_800 = g2.split('|')[-1]\n",
    "    url_600 = g2.split('|')[-2]\n",
    "    \n",
    "    return (url_600, url_800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "measured-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def exit(s):\n",
    "    s.get(f'{config.scheme}://{config.base_url}/logout/')\n",
    "    s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "399e1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ??????????????\n",
    "def get(text, cl):\n",
    "    b = BeautifulSoup(text, 'html.parser')\n",
    "    \n",
    "    # Костыль чтобы лишний раз не парсить файл для времени заливки файла\n",
    "    ctime = ''\n",
    "    arr = 0\n",
    "    \n",
    "    if (cl == config.class_pictures[\"file\"]) or (cl== config.class_files['file']) \\\n",
    "    or (cl== config.class_files['file_alt']) or (cl== config.class_music['file']):\n",
    "        mt = b.select('meta[itemprop=\"datePublished\"]')\n",
    "        \n",
    "        if (len(mt) > 0) and ('content' in mt[0].attrs.keys()):\n",
    "            ctime = mt[0].attrs['content']\n",
    "        else:\n",
    "            ctime = ''\n",
    "        \n",
    "        urls = b.select(cl)\n",
    "        arr = [ [ctime, url.attrs['href']] for url in urls]\n",
    "    else:\n",
    "        urls = b.select(cl)\n",
    "        arr = [ [url.text.strip().replace(os.sep, '_'), url.attrs['href']] for url in urls]\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3381c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Написать!!!!!111\n",
    "# Получаем куки из файла\n",
    "def get_cookie_from_file(name_file):\n",
    "\n",
    "    with open(name_file, 'r') as f:\n",
    "        js = f.read()\n",
    "    js2 = json.loads(js) if js is not None else ''\n",
    "\n",
    "    cook = requests.cookies.cookiejar_from_dict(js2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "896a0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем новую дату на файл\n",
    "def set_time_for_file(file_name, ctime):\n",
    "\n",
    "    # '2017-10-11T09:50:03+03:00'\n",
    "    t = time.strptime(ctime, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "    #  \"%a %b %d %H:%M:%S %Y\".\n",
    "    count_sec = time.mktime(t) \n",
    "    \n",
    "    os.utime(file_name, times = (count_sec, count_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddf030d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Добавляет к названию файла цифру, если такие файлы уже есть\n",
    "def enter_name_file(file_name):\n",
    "    while os.path.exists(file_name) == True:\n",
    "        filename, file_extension = os.path.splitext(file_name)\n",
    "            \n",
    "        ####\n",
    "        t = filename.split('_')\n",
    "        if len(t) > 1:\n",
    "            base_name = '_'.join( t[:-1] )\n",
    "            num = t[-1]\n",
    "            if num.isnumeric() == True:\n",
    "                num = str( int(num) + 1 )\n",
    "                filename = base_name + '_' + num\n",
    "            else:\n",
    "                filename += '_1'\n",
    "        else:\n",
    "            filename += '_1'\n",
    "\n",
    "        file_name = filename + file_extension \n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed676d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "def save_file(file_name, session, url, time = ''):\n",
    "    '''Скачиваем файл по ссылке и сохраняем на диск по указанному пути'''\n",
    "    \n",
    "    OK = 200\n",
    "    k = 100\n",
    "    batch = config.batch\n",
    "    i = 0\n",
    "    \n",
    "    # Скачиваю файл\n",
    "    info('='*k)\n",
    "    debug(f\"Скачиваю файл {file_name}\")\n",
    "    response = aget(session, url)\n",
    "        \n",
    "    if response != 0:\n",
    "        if response.status_code == OK:\n",
    "            debug(f'Скачал файл:\\n {url}')\n",
    "\n",
    "            #\n",
    "            file_name = enter_name_file(file_name)\n",
    "            #\n",
    "            if os.path.exists(file_name) != True:\n",
    "                try:\n",
    "                    with open(file_name, 'wb') as f:\n",
    "                        h = response.headers\n",
    "                        leng = 0\n",
    "                        total_it = 0\n",
    "                        if 'Accept-Ranges' in h.keys() and 'Content-Length' in h.keys():\n",
    "                            if h['Accept-Ranges'] == 'bytes' and h['Content-Length'].isnumeric():\n",
    "                                leng = int(h['Content-Length'])\n",
    "                                total_it = leng//batch + 1\n",
    "                        for chunk in tqdm(response.iter_content(batch), total=total_it):\n",
    "                            f.write(chunk)\n",
    "\n",
    "                    info(f\"OK --> {file_name} сохранен!\")\n",
    "                    info(time)\n",
    "                    info(url)\n",
    "                except Exception as e:\n",
    "                    error(f'Ошибка создания файла {file_name} = {e.args}')\n",
    "                    \n",
    "                    if i > config.limit:\n",
    "                        exit(0)\n",
    "                    else:\n",
    "                        i += 1\n",
    "\n",
    "            else:\n",
    "                error(f'Файл существует! ШТО??? {file_name}')\n",
    "\n",
    "            if time != '':\n",
    "                try:\n",
    "                    set_time_for_file(file_name, time)\n",
    "                    debug('Установил время')\n",
    "                except ValueError as e:\n",
    "                    error(f\"Ошибка с парсингом даты: {e.args}\")\n",
    "        else:\n",
    "            error(f'Ошибка = {response.status_code}')\n",
    "    else:\n",
    "        error(f\"response = {response};{url}\")\n",
    "        \n",
    "    info(f\"{'='*k}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3145ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указываем тип искомого объекта (файл, папка, страница с файлом ) и раздел в котором ищем (pictures, music, video, files)\n",
    "# Получаем строку для поиска записей о данном типе\n",
    "def get_class(tp, part):\n",
    "\n",
    "    if part == 'pictures':\n",
    "        return config.class_pictures[tp]\n",
    "    elif part == 'files':\n",
    "        return config.class_files[tp]\n",
    "    elif part == 'music':\n",
    "        return config.class_files[tp]\n",
    "    elif part == 'video':\n",
    "        return config.class_video[tp]\n",
    "    else:\n",
    "        return config.class_pictures[tp]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "divided-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Написать новый сборщик файлов - коллектор\n",
    "# Можно ли обойтись без рекурсии? Только на циклах\n",
    "def collecter(session, url, part, dirr):\n",
    "    \n",
    "    # Грузим страницу\n",
    "    text = aget(session, url).text\n",
    "\n",
    "    # Ищем ссылки на папки\n",
    "    cl = get_class('dir', part)\n",
    "    dirs = get(text, cl)\n",
    "        \n",
    "    # Ищем ссылки на страницы файлов\n",
    "    cl = get_class('page', part)\n",
    "    pages = get(text, cl)\n",
    "\n",
    "    for pg in pages:\n",
    "        text = aget(session, pg).text\n",
    "        file_url = get_file_url(text, part)\n",
    "            #\n",
    "        save_file(file_url)\n",
    "        \n",
    "    # Ищем следующую страницу\n",
    "    url = get_next_page2()\n",
    "    \n",
    "    if url != 0:\n",
    "        collecter(session, url, part, dirr)\n",
    "    else:\n",
    "        for dir_url in dirs:\n",
    "            collecter(session, dir_url, part, dirr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d62c7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "def start(session, url, part = '', dirr = ''):\n",
    "    \n",
    "    info(f'Грузим страницу {url}')\n",
    "    text = aget(session, url).text\n",
    "    \n",
    "    debug('Собираем ссылки на страницы')\n",
    "    # собираю ссылки на страницы с файлами\n",
    "    class_ = get_class(\"page\", part)\n",
    "    arr1 = get(text, class_)\n",
    "        \n",
    "    info(f\"Кол-во файлов на странице в папке = {len(arr1)}\")\n",
    "    \n",
    "    debug('Собираем ссылки на папки')\n",
    "    # собирают ссылки на папки\n",
    "    class_ = get_class(\"dir\", part)\n",
    "    arr2 = get(text, class_)\n",
    "    \n",
    "    info(f\"Кол-во папок на странице в папке = {len(arr2)}\")\n",
    "    \n",
    "    if len(arr2) > 0:\n",
    "        info(f\"Папки ==> { '; '.join( [a[0].strip() for a in arr2] ) }\")\n",
    "    \n",
    "    # если есть ссылки на страницы с файлам, то для каждой ссылки забираем ссылку на файл\n",
    "    if len(arr1) > 0:\n",
    "        debug('Забираем ссылки на файлы')\n",
    "        for a in arr1:\n",
    "            class_ = get_class(\"file\", part)\n",
    "            text2 = aget(session, a[1]).text\n",
    "            \n",
    "            ret = get( text2, class_)\n",
    "            \n",
    "            # Фотки размеров 800 и 600\n",
    "            ret800 = get_prev_pic(text2)\n",
    "            \n",
    "            #debug(f\"ret = {ret}\")\n",
    "            if part == 'files':\n",
    "                ret2 = get( text2, config.class_files['file_alt'] ) \n",
    "                ret = ret + ret2\n",
    "                #debug(f\"ret2 = {ret2}\")\n",
    "            \n",
    "            if len(ret) > 0:\n",
    "                # Скачиваем файл и сохраняем в папке dirr под именем\n",
    "                ctime = ret[0][0]\n",
    "                url_file = ret[0][1]\n",
    "                name_file = os.path.basename(url_file)\n",
    "                \n",
    "                #\n",
    "                url_file600 = ret800[0]\n",
    "                url_file800 = ret800[1]\n",
    "                #\n",
    "                name_file600 = os.path.basename(url_file600)\n",
    "                name_file800 = os.path.basename(url_file800)\n",
    "                \n",
    "                prev = 'prev'\n",
    "                if prev not in os.listdir(dirr):\n",
    "                    os.mkdir(dirr + os.sep + prev)\n",
    "                \n",
    "                save_file(dirr + os.sep + name_file, url_file, ctime)\n",
    "                save_file(dirr + os.sep + prev + os.sep + name_file600, url_file600, ctime)\n",
    "                save_file(dirr + os.sep + prev + os.sep + name_file800, url_file800, ctime)\n",
    "                \n",
    "                #info(name_file)\n",
    "\n",
    "    # Ищем след страницу\n",
    "    next_page = get_next_page2(text)\n",
    "    # Если есть следующая страница, то запускаем эту же функцию рекурсивно на ней\n",
    "    if next_page != 0:\n",
    "        info(f'Переходим на страницу {next_page} и ищем там')\n",
    "        start(session, next_page, part=part, dirr=dirr)\n",
    "    else:\n",
    "        debug('След страницы нет')\n",
    "       \n",
    "    # Если есть папки в папке, то в цикле рекурсивно запускаем эту же функцию\n",
    "    if len(arr2) > 0:\n",
    "        debug('Есть папки. Смотрим их')\n",
    "        for dir1 in arr2:\n",
    "            \n",
    "            name_dir = dir1[0].strip().replace(os.sep, '_')\n",
    "            url_dir = dir1[1]\n",
    "            \n",
    "            info(f\"Смотрим папку \\\"{ name_dir }\\\" \" )\n",
    "            \n",
    "            if name_dir not in os.listdir(dirr):\n",
    "                os.mkdir(dirr + os.sep + name_dir)\n",
    "                \n",
    "            start(session, url_dir, part=part, dirr = dirr + os.sep + name_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa4b59d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Старая точка входа\n",
    "def main_old():\n",
    "    ###\n",
    "    info('Погнали\\nПодключаюсь к учетке')\n",
    "    session = get_session(url_login)\n",
    "\n",
    "    for user in users:\n",
    "        for part in parts:\n",
    "            url = f'{config.scheme}://{config.base_url}/{part}/user/{user}/list/-/'\n",
    "            #\n",
    "            info(f'Смотрим юзера \"{user}\", раздел \"{part}\" ==> {url}')\n",
    "\n",
    "            if user not in os.listdir():\n",
    "                os.mkdir(user)\n",
    "\n",
    "            if part not in os.listdir(user):\n",
    "                os.mkdir(user + os.sep + part)\n",
    "            # Собираем ссылки, папки и проч\n",
    "            start(session, url, part = part, dirr=user + os.sep + part)\n",
    "\n",
    "            info(f'Раздел {part} юзера {user} завершен!')\n",
    "        info(f'Просмотр разделов юзера {user} завершен!')\n",
    "\n",
    "    session.close()\n",
    "    info('Работа завершена!')\n",
    "    info(f\"Просмотренные юзеры: { '; '.join(users) }\")\n",
    "    info(f\"Просмотренные разделы: { '; '.join(parts) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-prompt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "initial-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Удаляем все комменты из гости\n",
    "def delete_comment(s, url, time_wait):\n",
    "    \n",
    "    class_delete = 'a[data-action=\"comment_delete\"]'\n",
    "\n",
    "    r = aget(s, url)\n",
    "\n",
    "    i = 1\n",
    "    while url != 0:\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        ttt = bs.select(class_delete)\n",
    "\n",
    "        url = ttt[0].attrs['href'] if len(ttt) > 0 else 0\n",
    "        if url != 0:\n",
    "            print(f\"{i}; D--->{url}\")\n",
    "            r = aget(s, url)\n",
    "            i += 1\n",
    "            time.sleep(time_wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-generic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "level-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем данные о странице\n",
    "def get_metadata(text, stor):\n",
    "    \n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "\n",
    "    url_autor = bs.select('a[itemprop=\"url\"][class=\"mysite-link\"]')\n",
    "    autor = url_autor[0].text if len(url_autor) > 0 else ''\n",
    "    url_a = url_autor[0].attrs['href'] if len(url_autor) > 0 else ''\n",
    "\n",
    "    desc = bs.select('meta[content][itemprop=\"description\"]')\n",
    "    cont = desc[0].attrs['content'] if len(desc) > 0 else ''\n",
    "\n",
    "    dp = bs.select('meta[content][itemprop=\"datePublished\"]')\n",
    "    dp_c = dp[0].attrs['content'] if len(dp) > 0 else ''\n",
    "\n",
    "    ud = bs.select('meta[content][itemprop=\"uploadDate\"]')\n",
    "    ud_c = ud[0].attrs['content'] if len(ud) > 0 else ''\n",
    "\n",
    "    cs = bs.select('meta[content][itemprop=\"contentSize\"]')\n",
    "    cs_c = cs[0].attrs['content'] if len(cs) > 0 else ''\n",
    "\n",
    "    tmp = bs.select('div[class~=\"pad_t_a\"] span[class=\"break-word\"]')\n",
    "    des1 = tmp[0].text if len(tmp)>0 else ''\n",
    "\n",
    "    tmp = bs.select('div[class~=\"pad_t_a\"] a[class~=\"link-stnd\"]')\n",
    "    des2 = tmp[0].attrs['href'] if len(tmp)>0 else ''\n",
    "    des3 = tmp[0].text if len(tmp)>0 else ''\n",
    "\n",
    "    tmp = bs.select('div[class=\"pad_t_a break-word\"]')\n",
    "    desc_text = tmp[0].text if len(tmp)>0 else ''\n",
    "\n",
    "    meta = str(bs.select('meta'))\n",
    "\n",
    "    all_text = f\"Автор: {autor}\\n\"\\\n",
    "    f\"Ссылка на автора: {url_a}\\n\"\\\n",
    "    f\"Описание файла: {cont}\\n\"\\\n",
    "    f\"Дата публикации: {dp_c}\\n\"\\\n",
    "    f\"Дата загрузки: {ud_c}\\n\"\\\n",
    "    f\"Размер файла: {cs_c}\\n\"\\\n",
    "    f\"Папка: {des3}\\n\"\\\n",
    "    f\"Ссылка на папку: {des2}\\n\"\\\n",
    "    f\"Описание: {desc_text}\\n\"\\\n",
    "    f\"META:\\n{meta}\"\n",
    "    \n",
    "    \n",
    "    tmp = bs.select('meta[content][property=\"og:image\"]')\n",
    "    fff = tmp[0].attrs['content'] if len(tmp)>0 else 'tmp'\n",
    "    filename = os.path.basename(fff) + '.metadata'\n",
    "    \n",
    "    if 'metadata' not in os.listdir(stor):\n",
    "        os.mkdir(f\"{stor}{os.sep}metadata\")\n",
    "    \n",
    "    filename = enter_name_file(f\"{stor}{os.sep}metadata{os.sep}{filename}\")\n",
    "    with open(filename, 'a') as f:\n",
    "        print(all_text + '\\n', file=f)\n",
    "        \n",
    "    file_html = enter_name_file(f\"{stor}{os.sep}metadata{os.sep}{os.path.basename(fff)}.html\")\n",
    "    with open(file_html, 'w') as f2:\n",
    "        f2.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-freedom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-animal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-affiliate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-projection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "premier-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_bookmarks2(s, url_s):\n",
    "    i = 1\n",
    "    while url_s != 0:\n",
    "        r = aget(s, url_s)\n",
    "        url_s = get_next_page2(r.text)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        tt1 = bs.select('a[class=\"arrow_link\"]')\n",
    "\n",
    "        for ts in tt1:\n",
    "            r = aget(s, ts.attrs['href'])\n",
    "            bs = BeautifulSoup(r.text, 'html.parser')\n",
    "            tt = bs.select('a[class~=\"light_service_link\"]')\n",
    "\n",
    "            for t in tt:\n",
    "                url = t.attrs['href']\n",
    "                r = aget(s, url)\n",
    "                bs = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "                urls_del = bs.select('a[class=\"arrow_link\"]')\n",
    "                if len(urls_del)>0:\n",
    "                    url =urls_del[0].attrs['href']\n",
    "                    aget(s, url)\n",
    "                    info(f\"{i}: {url}\"); i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-steal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "nearby-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def delete_bookmarks(s, url):\n",
    "    \n",
    "    tt1 = [1, 3]\n",
    "    i = 1\n",
    "\n",
    "    while len(tt1) > 0:\n",
    "        r = aget(s, url)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        tt1 = bs.select('a[class=\"arrow_link\"]')\n",
    "\n",
    "\n",
    "        tt_new = tt1[0].attrs['href'] if len(tt1)>0 else 0\n",
    "        if tt_new != 0:\n",
    "            r = aget(s, url)\n",
    "            bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        ttt = bs.select('a[class~=\"light_service_link\"]')\n",
    "\n",
    "        for t in ttt:\n",
    "            u = t.attrs['href']\n",
    "            r = aget(s, u)\n",
    "            bs = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "            dd = bs.select('a[class=\"arrow_link\"]')\n",
    "            url_delete = dd[0].attrs['href'] if len(dd)>0 else 0\n",
    "\n",
    "            if url_delete != 0:\n",
    "                print(f\"{i}: {url_delete}\")\n",
    "                aget(s, url_delete)\n",
    "                i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-brush",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "consolidated-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список читателей с одной страницы\n",
    "def get_readers_one(text):\n",
    "    ns = BeautifulSoup(text, 'html.parser')\n",
    "    ttt = ns.select('div[class~=\"list-link__wrap\"] a[href]')\n",
    "\n",
    "    for t in ttt:\n",
    "        url = t.attrs['href']\n",
    "\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "going-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Достаём из страницы с файлом дату и время публикации\n",
    "def get_datePublished(text):\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    dt = bs.select('meta[itemprop=\"datePublished\"][content]')\n",
    "    \n",
    "    if len(dt) > 0:\n",
    "        return dt[0].attrs['content']\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "rocky-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Получаем обложку музыкального трека\n",
    "def get_cover_track(text):\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    ret = bs.select(config.class_music_cover)\n",
    "    \n",
    "    if len(ret) > 0:\n",
    "        return ret[0].attrs['href']\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-onion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "future-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_pic(s, res, part, stor):\n",
    "    # Дата публикации\n",
    "    dt = get_datePublished(res.text)\n",
    "    # Основной файл\n",
    "    file_urls = get_file_url(res.text, part)\n",
    "    for file_url in file_urls:\n",
    "        \n",
    "        if file_url.__contains__('/cs06.spac.me/'):\n",
    "            raise BaseException(-1)\n",
    "\n",
    "        ### Сам файл\n",
    "        name_file = stor + os.sep + os.path.basename(file_url)\n",
    "        name_file = enter_name_file(name_file)\n",
    "        debug(f\"{name_file} <-- {file_url}\")\n",
    "        save_file(name_file, s, file_url, dt)\n",
    "\n",
    "    # Сдвинул этот блок на 1 таб влево\n",
    "    # Превьюхи\n",
    "    if 'prev' not in os.listdir(stor):\n",
    "        os.mkdir(f\"{stor}{os.sep}prev\")\n",
    "    ff = get_prev_pic(res.text)\n",
    "    for f1 in ff:\n",
    "        name_file = f\"{stor}{os.sep}prev{os.sep}{os.path.basename(f1)}\"\n",
    "        name_file = enter_name_file(name_file)\n",
    "        debug(f\"{name_file} <-- {f1}\")\n",
    "        save_file(name_file, s, f1, dt)\n",
    "    # Прочие данные\n",
    "    if config.meta == True:\n",
    "        get_metadata(res.text, stor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "native-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_music(s, res, part, stor):\n",
    "    file_urls = get_file_url(res.text, part)\n",
    "    dt = get_datePublished(res.text)\n",
    "\n",
    "    for file_url in file_urls:\n",
    "        \n",
    "        if file_url.__contains__('/cs06.spac.me/'):\n",
    "            raise BaseException(-1)\n",
    "            \n",
    "        ### Сам файл\n",
    "        name_file = stor + os.sep + os.path.basename(file_url)\n",
    "        name_file = enter_name_file(name_file)\n",
    "        info(f\"{name_file} <-- {file_url}\")\n",
    "        save_file(name_file, s, file_url, dt)\n",
    "\n",
    "        if 'cover' not in os.listdir(stor):\n",
    "            os.mkdir(f\"{stor}{os.sep}cover\")\n",
    "\n",
    "    # Обложки, Подвинул блок\n",
    "    ff = get_cover_track(res.text)\n",
    "    if ff != '':\n",
    "        name_file = f\"{stor}{os.sep}cover{os.sep}{os.path.basename(ff)}\"\n",
    "        name_file = enter_name_file(name_file)\n",
    "\n",
    "        debug(f\"{name_file} <-- {ff}\")\n",
    "        save_file(name_file, s, ff, dt)\n",
    "        \n",
    "        # Превьюхи\n",
    "    if 'prev' not in os.listdir(stor):\n",
    "        os.mkdir(f\"{stor}{os.sep}prev\")\n",
    "    ff = get_prev_pic(res.text)\n",
    "    for f1 in ff:\n",
    "        name_file = f\"{stor}{os.sep}prev{os.sep}{os.path.basename(f1)}\"\n",
    "        name_file = enter_name_file(name_file)\n",
    "        debug(f\"{name_file} <-- {f1}\")\n",
    "        save_file(name_file, s, f1, dt)\n",
    "\n",
    "    # Прочие данные\n",
    "    if config.meta == True:\n",
    "        get_metadata(res.text, stor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "indirect-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_files(s, res, part, stor):\n",
    "    file_urls = get_file_url(res.text, part)\n",
    "    dt = get_datePublished(res.text)\n",
    "\n",
    "    for file_url in file_urls:\n",
    "        \n",
    "        if file_url.__contains__('/cs06.spac.me/'):\n",
    "            raise BaseException(-1)\n",
    "        \n",
    "        ### Сам файл\n",
    "        name_file = stor + os.sep + os.path.basename(file_url)\n",
    "        name_file = enter_name_file(name_file)\n",
    "        debug(f\"{name_file} <-- {file_url}\")\n",
    "        save_file(name_file, s, file_url, dt)\n",
    "        \n",
    "    # Превьюхи\n",
    "    if 'prev' not in os.listdir(stor):\n",
    "        os.mkdir(f\"{stor}{os.sep}prev\")\n",
    "    ff = get_prev_pic(res.text)\n",
    "    for f1 in ff:\n",
    "        name_file = f\"{stor}{os.sep}prev{os.sep}{os.path.basename(f1)}\"\n",
    "        name_file = enter_name_file(name_file)\n",
    "        debug(f\"{name_file} <-- {f1}\")\n",
    "        save_file(name_file, s, f1, dt)\n",
    "\n",
    "    # Прочие данные\n",
    "    if config.meta == True:\n",
    "        get_metadata(res.text, stor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "lonely-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_video(s, res, part, stor):\n",
    "    file_urls = get_file_url(res.text, part)\n",
    "    dt = get_datePublished(res.text)\n",
    "\n",
    "    for file_url in file_urls:\n",
    "        \n",
    "        if file_url.__contains__('/cs06.spac.me/'):\n",
    "            raise BaseException(-1)\n",
    "        \n",
    "        ### Сам файл\n",
    "        name_file = stor + os.sep + os.path.basename(file_url)\n",
    "        name_file = enter_name_file(name_file)\n",
    "        debug(f\"{name_file} <-- {file_url}\")\n",
    "        save_file(name_file, s, file_url, dt)\n",
    "        \n",
    "    # Превьюхи\n",
    "    if 'prev' not in os.listdir(stor):\n",
    "        os.mkdir(f\"{stor}{os.sep}prev\")\n",
    "    ff = get_prev_pic(res.text)\n",
    "    for f1 in ff:\n",
    "        name_file = f\"{stor}{os.sep}prev{os.sep}{os.path.basename(f1)}\"\n",
    "        name_file = enter_name_file(name_file)\n",
    "        debug(f\"{name_file} <-- {f1}\")\n",
    "        save_file(name_file, s, f1, dt)\n",
    "\n",
    "    # Прочие данные\n",
    "    if config.meta == True:\n",
    "        get_metadata(res.text, stor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "alternative-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Сборщик\n",
    "def coll(s, url, part, stor, limit = None):\n",
    "    # Получаем страницу\n",
    "    r = aget(s, url)\n",
    "    text = r.text\n",
    "    \n",
    "    # Получаем папки и файлы на странице\n",
    "    dirs = get_dir_page(text, part)\n",
    "    files_page= get_file_page(text, part)\n",
    "    count_files = len(files_page)\n",
    "    \n",
    "    info(f\"Папок: {len(dirs)}\")\n",
    "    info(f\"Файлов в папке: {count_files}\")\n",
    "\n",
    "    for dd1 in dirs:\n",
    "        if len(dd1) > 1:\n",
    "            info(f\"{dd1[0]} ===> {dd1[1]}\")\n",
    "        else:\n",
    "            error(f\"ERROR ? {dd1}\")\n",
    "    \n",
    "    i = 0\n",
    "    # для каждой страницы файла\n",
    "    for f_page in files_page:\n",
    "        i += 1\n",
    "        info(f\"Страница #{i}/{count_files} -- {f_page}\")\n",
    "\n",
    "        while True:\n",
    "            res = aget(s, f_page)\n",
    "            ts = random.randint(0, config.time_s2)\n",
    "            info(f\"Спим {ts} секунды\")\n",
    "            time.sleep(ts)\n",
    "            ##################\n",
    "            if part == 'pictures':\n",
    "                try:\n",
    "                    get_save_pic(s, res, part, stor)\n",
    "                    break\n",
    "                except BaseException as e:\n",
    "                    error('Вот она!')\n",
    "            ##############\n",
    "            if part == 'pic_top':\n",
    "                try:\n",
    "                    get_save_pic(s, res, 'pictures', stor)\n",
    "                    break\n",
    "                except BaseException as e:\n",
    "                    error('Вот она!')\n",
    "            ##############\n",
    "            elif part == 'music':\n",
    "                try:\n",
    "                    get_save_music(s, res, part, stor)\n",
    "                    break\n",
    "                except BaseException as e:\n",
    "                    error('Вот она!')\n",
    "            ##############  \n",
    "            elif part == 'files':\n",
    "                try:\n",
    "                    get_save_files(s, res, part, stor)\n",
    "                    break\n",
    "                except BaseException as e:\n",
    "                    error('Вот она!')\n",
    "            ##############\n",
    "            elif part == 'video':\n",
    "                try:\n",
    "                    get_save_video(s, res, part, stor)\n",
    "                    break\n",
    "                except BaseException as e:\n",
    "                    error('Вот она!')\n",
    "\n",
    "    if (limit == None) or (limit > 0):\n",
    "        url_new = get_next_page2(text)\n",
    "        if url_new != 0:\n",
    "            info(f\"Следующая страница --> {url_new}\")\n",
    "            if limit == None:\n",
    "                coll(s, url_new, part, stor)\n",
    "            elif limit > 0:\n",
    "                coll(s, url_new, part, stor, limit-1)\n",
    "        \n",
    "    for dir1 in dirs:\n",
    "        if len(dir1) == 2:\n",
    "            name_dir = dir1[0].replace(os.sep, '_')\n",
    "            url_dir  = dir1[1]\n",
    "            if name_dir not in os.listdir(stor):\n",
    "                os.mkdir(stor +os.sep+ name_dir)\n",
    "            \n",
    "            info(f\"Захожу в папку {name_dir}\")\n",
    "            coll(s, url_dir, part, stor + os.sep + name_dir)\n",
    "        else:\n",
    "            error(f\"ERROR --> {dir1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abroad-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssstart(user_target, part):\n",
    "    links = get_autolink('autolinks.txt')\n",
    "    login_url = links['Pussy__Riot']\n",
    "\n",
    "    session = get_session(login_url)\n",
    "\n",
    "    url_target = f'https://spcs.pro/{part}/user/{user_target}/list/-/'\n",
    "\n",
    "    if config.base_url not in os.listdir():\n",
    "        os.mkdir(config.base_url)\n",
    "    if user_target not in os.listdir(config.base_url):\n",
    "        os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "    if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "        os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "\n",
    "    stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "    coll(session, url_target, part, stor)\n",
    "    exit(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-absence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "surprising-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'div[class~=\"__adv_download\"] a[href]'\n",
    "### 'a.gview_link[href]'\n",
    "### dev[class=\"att_wrap\"] a[href]\n",
    "def get_file_from_post(s, text, stor, select, part):\n",
    "\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    urls = bs.select(select)\n",
    "\n",
    "    for url in urls:\n",
    "        url_ = url['href']\n",
    "        if url_.__contains__('https://') or url_.__contains__('http://'):\n",
    "            info(url_)\n",
    "            \n",
    "            i = 0\n",
    "            while i < 10:\n",
    "                name = os.path.basename(url_)\n",
    "                name = enter_name_file(f\"{stor}{os.sep}{name}\")\n",
    "                try:\n",
    "                    save_file(name, s, url_, '')\n",
    "                    i = 13\n",
    "                except BaseException as e:\n",
    "                    error(f'Проблема 6 сервера: {str(e)}'); i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "internal-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### На странице находим ссылки на страницы с фотографиями и скачиваем фотки\n",
    "#  dev[class=\"att_wrap\"] a[href]\n",
    "# 'a.gview_link[href]'\n",
    "def get_pics_from_post(s, text, stor, select, part):\n",
    "\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    all_pic = bs.select(select)\n",
    "\n",
    "    for pic in all_pic:\n",
    "        url_pic = pic['href']\n",
    "        \n",
    "        if not (url_pic.__contains__('https://') or url_pic.__contains__('http://')):\n",
    "            error('Не ссылка')\n",
    "            return\n",
    "        \n",
    "        if url_pic.__contains__('/video/'):\n",
    "            part = 'video'\n",
    "            \n",
    "        print(url_pic)\n",
    "\n",
    "        i = 0\n",
    "        while i < 10:\n",
    "            r = aget(s, url_pic)\n",
    "            dt = get_datePublished(r.text)\n",
    "            urls_save = get_file_url(r.text, part)\n",
    "            prevs = get_prev_pic(r.text)\n",
    "\n",
    "            for p in prevs:\n",
    "                name = os.path.basename(p)\n",
    "                name = enter_name_file(f\"{stor}{os.sep}{name}\")\n",
    "                try:\n",
    "                    save_file(name, s, p, dt)\n",
    "                except BaseException as e:\n",
    "                    error(f'Проблема 6 сервера: {str(e)}'); i+=1\n",
    "\n",
    "            for url_save in urls_save:\n",
    "                name = os.path.basename(url_save)\n",
    "                name = enter_name_file(f\"{stor}{os.sep}{name}\")\n",
    "                try:\n",
    "                    save_file(name, s, url_save, dt)\n",
    "                    i = 13\n",
    "                except BaseException as e:\n",
    "                    error(f'Проблема 6 сервера: {str(e)}'); i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "informal-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def get_title_page(text):\n",
    "    bs = BeautifulSoup(text, 'html.parser')\n",
    "    ss = bs.select('title')\n",
    "    title = ss[0].get_text().strip().replace(':', '_').replace(' ', '_').replace(os.sep, ';') if len(ss) > 0 else 'tmp'\n",
    "    \n",
    "    return str(title)[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bacterial-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вытаскиваем теги с атрибутом src, достаём из него ссылки и скачиваем\n",
    "def get_src_post(s, html, dir_d):\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    # Сохраняем картинки из тегов img\n",
    "    tt = bs.select('[src]')\n",
    "    \n",
    "    for t in tt:\n",
    "        # src который поменяем на локальный путь\n",
    "        url_old = t.attrs['src']\n",
    "        if url_old.__contains__('https://') or url_old.__contains__('http://'):\n",
    "            # картинка которую скачиваем\n",
    "            url_pic = url_old\n",
    "            tag_old = t\n",
    "            # название картинки\n",
    "            namefile = os.path.basename(url_pic)\n",
    "            #Путь по которому будет лежать скачанная картинка\n",
    "            url_save = enter_name_file(f\"{dir_d}{os.sep}{namefile}\")\n",
    "            url_new = f\"{url_save.split(os.sep)[-2]}{os.sep}{url_save.split(os.sep)[-1]}\"\n",
    "            \n",
    "            tag_new = str(tag_old).replace(url_old, url_new)\n",
    "            t.replace_with(BeautifulSoup(tag_new, 'html.parser'))\n",
    "            \n",
    "            save_file(url_save, s, url_pic)\n",
    "\n",
    "            debug(f\"Скачиваем картинку {url_pic}\")\n",
    "            debug(f\"Называем скачанную картинку как {url_save}\")\n",
    "            debug(f\"Переименовываем {url_old} ===> {url_new}\")\n",
    "\n",
    "        else:\n",
    "            debug('else')\n",
    "            # Нужно сформировать новый тег, где старый src нужно заменить на локальную ссылку скачанного из data-s файла\n",
    "            # Картинка, которую скачиваем\n",
    "            url_pic = t.attrs['data-s']\n",
    "            tag_old = t\n",
    "            \n",
    "            # Название картинки которую скачаем\n",
    "            namefile = os.path.basename(url_pic)\n",
    "            # путь, по которому будет лежать скачанная картинка\n",
    "            url_save = enter_name_file(f\"{dir_d}{os.sep}{namefile}\")\n",
    "            url_new = f\"{url_save.split(os.sep)[-2]}{os.sep}{url_save.split(os.sep)[-1]}\"\n",
    "            # Заменяем старый путь на локальный\n",
    "            tag_new = str(tag_old).replace(url_old, url_new)\n",
    "            t.replace_with(BeautifulSoup(tag_new, 'html.parser'))\n",
    "            \n",
    "            save_file(url_save, s, url_pic)\n",
    "\n",
    "            debug(f\"Скачиваем картинку {url_pic}\")\n",
    "            debug(f\"Называем скачанную картинку как {url_save}\")\n",
    "            debug(f\"Переименовываем {url_old} ===> {url_new}\")\n",
    "            \n",
    "    return str(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "diagnostic-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def delete_diary(session, url):\n",
    "\n",
    "    i = 1\n",
    "    while True:\n",
    "        r = aget(session, url)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        ttt = bs.select('a[class~=\"tdn\"]')\n",
    "\n",
    "        for t in ttt:\n",
    "            lol = t.attrs['href'].split('/')[7]\n",
    "            id_ = 0\n",
    "            if len(lol.split('-')) > 1:\n",
    "                id_ = lol.split('-')[1]\n",
    "            else:\n",
    "                id_ = lol\n",
    "\n",
    "            url_del = f\"{config.scheme}://{config.base_url}/diary/delete/?id={id_}\"\n",
    "            rrr = aget(session, url_del)\n",
    "            bs2 = BeautifulSoup(rrr.text)\n",
    "            ddd = bs2.select('a.stnd-link.list-link-blue.c-blue')\n",
    "            url_del = ddd[0].attrs['href']\n",
    "            aget(session, url_del)\n",
    "            info(f\"{i}: {url_del}\"); i+=1\n",
    "\n",
    "        #url = get_next_page2(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-description",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-victoria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-liver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-volleyball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "genuine-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Скачиваем одну страницу с сайта с картинками и сохраняем\n",
    "def download_one_page(s, url, time_st, number_page, stor):\n",
    "    r = aget(s, url)\n",
    "    html = r.text\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    # Название страницы\n",
    "    title = f\"{get_title_page(html)}_{time_st}\"\n",
    "    dir_d = enter_name_file(f\"{stor}{os.sep}{title}{os.sep}page_{number_page}_files\")\n",
    "    dir_d1 = dir_d.split('/')[-1]\n",
    "    \n",
    "    if title not in os.listdir(stor):\n",
    "        os.mkdir(f\"{stor}{os.sep}{title}\")\n",
    "    if dir_d not in os.listdir(f\"{stor}{os.sep}{title}\"):\n",
    "        os.mkdir(dir_d)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    # Скачиваем превьюшки, переписываем теги\n",
    "    html = get_src_post(s, html, dir_d)\n",
    "    #\n",
    "    ################################\n",
    "    # Сохраняем страницу\n",
    "    with open(f\"{stor}{os.sep}{title}{os.sep}page_{number_page}.html\", 'w') as f:\n",
    "        f.write(html)\n",
    "        \n",
    "    # Страницы с раскрытыми сообщениями (если есть свёрнутые)\n",
    "    desc_tt = bs.select('a[class=\"splr_item js-message_show\"][href]')\n",
    "    for desc_t in desc_tt:\n",
    "        url_desc = desc_t['href']\n",
    "        fdesc = enter_name_file(f\"{dir_d}{os.sep}{number_page}_desc.html\")\n",
    "        if \"desc\" not in os.listdir(dir_d):\n",
    "            os.mkdir(f\"{dir_d}{os.sep}desc\")\n",
    "        \n",
    "        r_n = aget(s, url_desc)\n",
    "        r_nt = get_src_post(s, r_n.text, f\"{dir_d}{os.sep}desc\")\n",
    "\n",
    "        with open(fdesc, 'w') as f:\n",
    "            f.write(r_nt)\n",
    "\n",
    "        if \"test\" not in os.listdir(f\"{dir_d}{os.sep}desc\"):\n",
    "            os.mkdir(f\"{dir_d}{os.sep}desc{os.sep}test\")\n",
    "        get_pics_from_post(s, r_n.text, f\"{dir_d}{os.sep}desc{os.sep}test\", 'a.gview_link[href]', 'pictures')\n",
    "   \n",
    "\n",
    "    if \"test\" not in os.listdir(dir_d):\n",
    "        os.mkdir(f\"{dir_d}{os.sep}test\")\n",
    "\n",
    "    get_pics_from_post(s, r.text, f\"{dir_d}/test\", 'a.gview_link[href]', 'pictures')\n",
    "    get_pics_from_post(s, r.text, f\"{dir_d}/test\", 'div[class=\"att_wrap\"] a[href][class~=\"link-stnd\"]', 'files')\n",
    "    get_file_from_post(s, r.text, f\"{dir_d}/test\", 'div[class~=\"__adv_download\"] a[href]', 'music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "internal-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "def download_one_elem(session, url, stor):\n",
    "    time_st = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "    k = 1\n",
    "    while url != 0:\n",
    "        info(f\"Страница #{k}\")\n",
    "        download_one_page(session, url, time_st, k, stor)\n",
    "        r = aget(session, url)\n",
    "        url = get_next_page2(r.text)\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-arlington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-works",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-respect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-retirement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e761df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dominant-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = OptionParser()\n",
    "\n",
    "# Сервисные\n",
    "parser.add_option(\"-i\", \"--input\", dest=\"input\", help=\"Файл с логинами\", metavar=\"FILE\")\n",
    "parser.add_option(\"-A\", \"--auto-links\", dest=\"al\", help=\"Брать автовходы из файла\", metavar=\"FILE\")\n",
    "parser.add_option(\"-I\", \"--into-account\", dest=\"into\", help=\"Войти в аккаунт\", metavar=\"LOGIN\")\n",
    "parser.add_option(\"-R\", \"--rotation-al\", dest=\"rotation\", action=\"store_true\",default=False, help=\"Ротация автовходов\")\n",
    "parser.add_option(\"-c\", \"--comm\", dest=\"community\", action=\"store_true\",default=False, help=\"Скачиваем из сообщества (По умолчанию - пользователь)\")\n",
    "\n",
    "# Лёгкие\n",
    "parser.add_option(\"-n\", \"--nick\", dest=\"nick\", action=\"store_true\",default=False, help=\"Посмотреть никнэйм\")\n",
    "parser.add_option('-s', '--status', dest='status', action='store_true', default=False, help='Получить статус')\n",
    "parser.add_option('-a', '--avatar', dest='avatar', action='store_true', default=False, help='Скачать аватар, new')\n",
    "parser.add_option(\"-b\", \"--bookmarks\", dest=\"bookmarks\", action=\"store_true\",default=False, help=\"Собрать закладки, new\")\n",
    "parser.add_option('-g', '--guestbook', dest='guestbook', action='store_true', default=False, help='Всё забрать из гостевой')\n",
    "parser.add_option('',   '--post', dest='post', action='store_true', default=False, help='Всё забрать из почты')\n",
    "parser.add_option('',   '--diary', dest='diary', action='store_true', default=False, help='Всё забрать из дневника')\n",
    "parser.add_option(\"-0\", \"--one-element-html\", dest=\"one_element\", help=\"hhh\", metavar=\"url\")\n",
    "\n",
    "# Основные - файловые\n",
    "parser.add_option('-P', '--pictures', dest='pictures', action='store_true', default=False, help='Забираем фотографии, new')\n",
    "parser.add_option(\"-M\", \"--music\", dest=\"music\", action='store_true', default=False, help='Забираем музыку, new')\n",
    "parser.add_option(\"-V\", \"--video\", dest=\"video\", action='store_true', default=False, help='Забираем видео, new')\n",
    "parser.add_option('-F', '--files', dest='files', action='store_true', default=False, help='Забираем файлы, new')\n",
    "\n",
    "# Коллекции основных\n",
    "parser.add_option('-p', '--pictures_collection', dest='pictures_collection', action='store_true', default=False, help='Собрать из коллекций фотографий, new')\n",
    "parser.add_option('-v', '--video_collection', dest='video_collection', action='store_true', default=False, help='Собрать из коллекций видео, new')\n",
    "parser.add_option('-f', '--files_collection', dest='files_collection', action='store_true', default=False, help='Собрать из коллекций файлов, new')\n",
    "\n",
    "# Скачиваем отдельную папку из раздела картинки\n",
    "parser.add_option('-1', '--pictures_dir', dest='pictures_dir', action='store_true', default=False, help='Забрать отдельную папку с подпапками из раздела pictures, new')\n",
    "# Скачиваем отдельную папку из раздела файлы\n",
    "parser.add_option('-2', '--files_dir', dest='files_dir', action='store_true', default=False, help='Забрать отдельную папку с подпапками из раздела files, new')\n",
    "# Скачиваем отдельную папку из раздела видео\n",
    "parser.add_option('-3', '--video_dir', dest='video_dir', action='store_true', default=False, help='Забрать отдельную папку с подпапками из раздела video, new')\n",
    "# Скачиваем отдельную папку из раздела музыка\n",
    "parser.add_option('-4', '--music_dir', dest='music_dir', action='store_true', default=False, help='Забрать отдельную папку с подпапками из раздела music, new')\n",
    "#\n",
    "parser.add_option('', '--pictures_top', dest='pic_top', action='store_true', default=False, help='Фотографии с главной. Лимит страниц указывается аргументом')\n",
    "\n",
    "\n",
    "# Прочее\n",
    "parser.add_option('-r', '--readers', dest='readers', action='store_true', default=False, help='Забираем читателей')\n",
    "parser.add_option('-H', '--history_login', dest='history_login', action='store_true', default=False, help='Смотрим историю входов на аккаунте')\n",
    "parser.add_option('-l', '--likes', dest='likes', action='store_true', default=False, help='Список того, что вы лайкали')\n",
    "parser.add_option('-C', '--comm-list', dest='comm_list', action='store_true', default=False, help='Список сообществ пользователей заданных списком аргументов')\n",
    "parser.add_option('', '--delete-bookmarks', dest='del_bookmarks', action='store_true', default=False, help='Удаляем закладки')\n",
    "parser.add_option('', '--delete-comment-guestbook', dest='del_comm', action='store_true', default=False, help='Удаляем комменты из гостевой')\n",
    "\n",
    "\n",
    "#parser.add_option('-m', '--main_old', dest='main_old', action='store_true', default=False, help='Запустить старую точку входа')\n",
    "#oparser.add_option(\"-h\", \"--help\", dest=\"hel\", action=\"store_true\",default=False, help=\"Справка\")\n",
    "\n",
    "(options, args) = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-reader",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-columbia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-egyptian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "miniature-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Берём случайный user-agent\n",
    "headers = { 'User-Agent': random_ua()[0] }\n",
    "# Если автовход не задан - заходим на сайт как гость\n",
    "url_login = f\"{config.scheme}://{config.base_url}/\"\n",
    "links = []\n",
    "login = ''\n",
    "# Статистика подключений\n",
    "stat = {'count_session': 0, 'count_disconnect': 0, 'count_reconnect': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "driven-willow",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2023-02-25 00:15:11,814 - INFO - Собираем коллекции файлов\n",
      " 2023-02-25 00:15:11,816 - INFO - https://spcs.pro/files/collections//home/kapalua/.local/share/jupyter/runtime/kernel-06872115-f0c9-416f-9d3a-c1b0d01ab20b.json/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spcs.pro//home/kapalua/.local/share/jupyter/runtime/kernel-06872115-f0c9-416f-9d3a-c1b0d01ab20b.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-232038f6e89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_target\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{config.base_url}{os.sep}{user_target}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{config.base_url}{os.sep}{user_target}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spcs.pro//home/kapalua/.local/share/jupyter/runtime/kernel-06872115-f0c9-416f-9d3a-c1b0d01ab20b.json'"
     ]
    }
   ],
   "source": [
    "############# Точки входа #############\n",
    "\n",
    "############ Автовходы ###############\n",
    "# Если задан файл со списоком автовходов\n",
    "if options.al is not None:\n",
    "    file = str(options.al)\n",
    "    # Словарь {логин: автовход}\n",
    "    links = get_autolink(file)\n",
    "    \n",
    "    # Если задан нужный логин из списка - выбираем его\n",
    "    if options.into is not None:\n",
    "        login = str(options.into)\n",
    "        \n",
    "        if login in links.keys():\n",
    "            url_login = links[login]\n",
    "        else:\n",
    "            error('Нет такого автовхода')\n",
    "        \n",
    "    # Если логин не задан - выбираем по умолчанию первый\n",
    "    else:\n",
    "        for login in links.keys():\n",
    "            url_login = links[login]\n",
    "            break\n",
    "       \n",
    "    session = get_session(url_login)\n",
    "    info(f\"Захожу по аккаунтом {login}: {url_login}\")\n",
    "\n",
    "############ Ник ###################################\n",
    "if options.nick == True:\n",
    "    debug('Смотрим никнэйм')\n",
    "    #\n",
    "    #session = get_session(url_login)\n",
    "    nick = get_nick(session)\n",
    "    print(nick)\n",
    "    \n",
    "    #exit(session)\n",
    "\n",
    "############ Аватар #################################\n",
    "if options.avatar == True:\n",
    "    debug('avatar')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "    \n",
    "    #session = get_session(url_login)\n",
    "    for user in users:\n",
    "        url = f\"{config.scheme}://{config.base_url}/mysite/index/{user}/\"\n",
    "        r = aget(session, url)\n",
    "\n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user}\")\n",
    "        if 'avatar' not in os.listdir(f\"{config.base_url}{os.sep}{user}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user}{os.sep}avatar\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user}{os.sep}avatar\"\n",
    "\n",
    "        get_avatar(session, r.text, stor)\n",
    "    \n",
    "    #exit(session)\n",
    "############# Статус ################################\n",
    "if options.status == True:\n",
    "    debug('status')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "    \n",
    "    #session = get_session(url_login)\n",
    "    for user in users:\n",
    "        url = f\"{config.scheme}://{config.base_url}/mysite/index/{user}/\"\n",
    "        res = aget(session, url)\n",
    "        status = get_status_from_userpage(res.text)\n",
    "        print(f\"{user};{status}\")\n",
    "        \n",
    "    #exit(session)\n",
    "############# Анкета ##################################\n",
    "\n",
    "############# Гостевая #################################\n",
    "if options.guestbook == True:\n",
    "    debug('Гостевая')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "    \n",
    "    for user in users:\n",
    "        info(user)\n",
    "\n",
    "        part = 'guestbook'\n",
    "        #\n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user}\"\n",
    "        if part not in os.listdir(stor):\n",
    "            os.mkdir(f\"{stor}{os.sep}{part}\")\n",
    "        stor = f\"{stor}{os.sep}{part}\"\n",
    "        \n",
    "        url = f'{config.scheme}://{config.base_url}/{part}/index/{user}/'\n",
    "        info(f'Гостевая {user}\\n')\n",
    "        \n",
    "        download_one_elem(session, url, stor)\n",
    "        \n",
    "        info(f\"Всё вывел\")\n",
    "        \n",
    "        #exit(session)\n",
    "############## Блог ####################################\n",
    "\n",
    "############## Собираем закладки #########################\n",
    "if options.bookmarks == True and options.al is not None:\n",
    "    debug('Собираем закладки')\n",
    "        \n",
    "    if config.base_url not in os.listdir():\n",
    "        os.mkdir(config.base_url)\n",
    "    dirr = f\"{config.base_url}{os.sep}{login}\"\n",
    "    if login not in os.listdir(config.base_url):\n",
    "        os.mkdir(dirr)\n",
    "\n",
    "    #session = get_session(url_login)\n",
    "    dt = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "    file = f\"{dirr}{os.sep}bookmarks_{login}_{dt}.txt\"\n",
    "    get_bookmarks_all(session, file)\n",
    "    info(f\"-->{file}\")\n",
    "    \n",
    "    #exit(session)\n",
    "##################### Фотографии ###################### new\n",
    "if options.pictures == True:\n",
    "    info('Собираем картинки')\n",
    "    \n",
    "    users = []\n",
    "    \n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    type_site = 'user'\n",
    "    if options.community == True:\n",
    "        type_site = 'comm' \n",
    "\n",
    "    for user_target in users:\n",
    "        #session = get_session(url_login)\n",
    "        \n",
    "        part = 'pictures'\n",
    "        url_target = f'{config.scheme}://{config.base_url}/{part}/{type_site}/{user_target}/list/-/'\n",
    "\n",
    "        info(url_target)\n",
    "        \n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user_target not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "        if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "\n",
    "        coll(session, url_target, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "################# Фотографии/Коллекции ####################### new\n",
    "if options.pictures_collection == True:\n",
    "    info('Собираем коллекции фотографий')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    for user_target in users:\n",
    "        #session = get_session(url_login)\n",
    "        \n",
    "        part = 'pictures'\n",
    "        url_target = f'{config.scheme}://{config.base_url}/{part}/collections/{user_target}/'\n",
    "        \n",
    "        info(url_target)\n",
    "        \n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user_target not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "        if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "        if 'collection' not in os.listdir(stor):\n",
    "            os.mkdir(f\"{stor}{os.sep}collection\")\n",
    "        stor = f\"{stor}{os.sep}collection\"\n",
    "\n",
    "        coll(session, url_target, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "#################### Музыка ################## new\n",
    "if options.music == True:\n",
    "    info('Собираем музыку')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    type_site = 'user'\n",
    "    if options.community == True:\n",
    "        type_site = 'comm'\n",
    "    \n",
    "    for user_target in users:\n",
    "        #session = get_session(url_login)\n",
    "        \n",
    "        part = 'music'\n",
    "        url_target = f'{config.scheme}://{config.base_url}/{part}/{type_site}/{user_target}/list/-/'\n",
    "\n",
    "        info(url_target)\n",
    "        \n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user_target not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "        if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "\n",
    "        coll(session, url_target, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "\n",
    "############ Видео ############## new\n",
    "if options.video == True:\n",
    "    info('Собираем видео')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    type_site = 'user'\n",
    "    if options.community == True:\n",
    "        type_site = 'comm'        \n",
    "\n",
    "    for user_target in users:\n",
    "        #session = get_session(url_login)\n",
    "        \n",
    "        part = 'video'\n",
    "        url_target = f'{config.scheme}://{config.base_url}/{part}/{type_site}/{user_target}/list/-/'\n",
    "\n",
    "        info(url_target)\n",
    "        \n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user_target not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "        if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "\n",
    "        coll(session, url_target, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "\n",
    "############# Видео, коллекции ############# new \n",
    "if options.video_collection == True:\n",
    "    info('Собираем коллекции видео')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    for user_target in users:\n",
    "        #session = get_session(url_login)\n",
    "        \n",
    "        part = 'video'\n",
    "        url_target = f'{config.scheme}://{config.base_url}/{part}/collections/{user_target}/'\n",
    "        \n",
    "        info(url_target)\n",
    "        \n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user_target not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "        if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "        if 'collection' not in os.listdir(stor):\n",
    "            os.mkdir(f\"{stor}{os.sep}collection\")\n",
    "        stor = f\"{stor}{os.sep}collection\"\n",
    "\n",
    "        coll(session, url_target, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "############# Файлы ############# new\n",
    "if options.files == True:\n",
    "    info('Собираем файлы')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    type_site = 'user'\n",
    "    if options.community == True:\n",
    "        type_site = 'comm'        \n",
    "\n",
    "    for user_target in users:\n",
    "        #session = get_session(url_login)\n",
    "        \n",
    "        part = 'files'\n",
    "        url_target = f'{config.scheme}://{config.base_url}/{part}/{type_site}/{user_target}/list/-/'\n",
    "\n",
    "        info(url_target)\n",
    "        \n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user_target not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "        if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "\n",
    "        coll(session, url_target, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "############## Файлы/Коллекции ############ new\n",
    "if options.files_collection == True:\n",
    "    info('Собираем коллекции файлов')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    elif options.input is not None:\n",
    "        users = get_users(options.input)\n",
    "    else:\n",
    "        error(\"Задайте пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    for user_target in users:\n",
    "        #session = get_session(url_login)\n",
    "        \n",
    "        part = 'files'\n",
    "        url_target = f'{config.scheme}://{config.base_url}/{part}/collections/{user_target}/'\n",
    "        \n",
    "        info(url_target)\n",
    "        \n",
    "        if config.base_url not in os.listdir():\n",
    "            os.mkdir(config.base_url)\n",
    "        if user_target not in os.listdir(config.base_url):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}\")\n",
    "        if part not in os.listdir(f\"{config.base_url}{os.sep}{user_target}\"):\n",
    "            os.mkdir(f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\")\n",
    "        stor = f\"{config.base_url}{os.sep}{user_target}{os.sep}{part}\"\n",
    "        if 'collection' not in os.listdir(stor):\n",
    "            os.mkdir(f\"{stor}{os.sep}collection\")\n",
    "        stor = f\"{stor}{os.sep}collection\"\n",
    "\n",
    "        coll(session, url_target, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "#############  Скачивание отдельных папок ################\n",
    "# Отдельная папка из картинок\n",
    "if options.pictures_dir == True:\n",
    "    info('Скачиваем отдельную папку с подпапками из картинок')\n",
    "    \n",
    "    links = []\n",
    "    if len(args) > 0:\n",
    "        links = args\n",
    "    else:\n",
    "        error(\"Задайте URL папки\")\n",
    "        exit(0)\n",
    "\n",
    "    for link in links:\n",
    "        #session = get_session(url_login)\n",
    "        part = 'pictures'\n",
    "        dt = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "        stor = f\"{part}_{dt}\"\n",
    "        info(f\"{stor} <-- {link}\")\n",
    "        \n",
    "        if stor not in os.listdir():\n",
    "            os.mkdir(stor)\n",
    "\n",
    "        coll(session, link, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "\n",
    "# Отдельная папка из файлов\n",
    "if options.files_dir == True:\n",
    "    info('Скачиваем отдельную папку с подпапками из файлов')\n",
    "    \n",
    "    links = []\n",
    "    if len(args) > 0:\n",
    "        links = args\n",
    "    else:\n",
    "        error(\"Задайте URL папки\")\n",
    "        exit(0)\n",
    "\n",
    "    for link in links:\n",
    "        #session = get_session(url_login)\n",
    "        part = 'files'\n",
    "        dt = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "        stor = f\"{part}_{dt}\"\n",
    "        info(f\"{stor} <-- {link}\")\n",
    "        \n",
    "        if stor not in os.listdir():\n",
    "            os.mkdir(stor)\n",
    "\n",
    "        coll(session, link, part, stor)\n",
    "        \n",
    "        #exit(session)        \n",
    "        \n",
    "# Отдельная папка из видео\n",
    "if options.video_dir == True:\n",
    "    info('Скачиваем отдельную папку с подпапками из видео')\n",
    "    \n",
    "    links = []\n",
    "    if len(args) > 0:\n",
    "        links = args\n",
    "    else:\n",
    "        error(\"Задайте URL папки\")\n",
    "        exit(0)\n",
    "\n",
    "    for link in links:\n",
    "        #session = get_session(url_login)\n",
    "        part = 'video'\n",
    "        dt = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "        stor = f\"{part}_{dt}\"\n",
    "        info(f\"{stor} <-- {link}\")\n",
    "        \n",
    "        if stor not in os.listdir():\n",
    "            os.mkdir(stor)\n",
    "\n",
    "        coll(session, link, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "\n",
    "# Отдельная папка из музыки\n",
    "if options.music_dir == True:\n",
    "    info('Скачиваем отдельную папку с подпапками из музыки')\n",
    "    \n",
    "    links = []\n",
    "    if len(args) > 0:\n",
    "        links = args\n",
    "    else:\n",
    "        error(\"Задайте URL папки\")\n",
    "        exit(0)\n",
    "\n",
    "    for link in links:\n",
    "        #session = get_session(url_login)\n",
    "        part = 'music'\n",
    "        dt = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "        stor = f\"{part}_{dt}\"\n",
    "        \n",
    "        info(f\"{stor} <-- {link}\")\n",
    "        \n",
    "        if stor not in os.listdir():\n",
    "            os.mkdir(stor)\n",
    "\n",
    "        coll(session, link, part, stor)\n",
    "        \n",
    "        #exit(session)\n",
    "\n",
    "######################## Сообщества ######################\n",
    "if options.comm_list == True:\n",
    "    \n",
    "    info('Список сообществ')\n",
    "\n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    else:\n",
    "        error(\"Задайте целевого пользователя\")\n",
    "        exit(0)\n",
    "    \n",
    "    #session = get_session(url_login)\n",
    "\n",
    "    for user in users:\n",
    "        url = f\"{config.scheme}://{config.base_url}/comm/list/user/{user}/\"\n",
    "\n",
    "        print(f\"{user}:\\n\")\n",
    "        \n",
    "        while url != 0:\n",
    "            r = aget(session, url)\n",
    "            bs = BeautifulSoup(r.text, 'html.parser')\n",
    "            items = bs.select('div[class~=\"content-item3\"] a[class~=\"tdn\"][href]')\n",
    "\n",
    "            for i, item in enumerate(items):\n",
    "                text = item.text.strip()\n",
    "                href = item.attrs['href']\n",
    "                print(f\"{i+1}: {text};{href}\")\n",
    "\n",
    "            url = get_next_page2(r.text)\n",
    "\n",
    "    #exit(session)\n",
    "###########################################################\n",
    "# Друзья\n",
    "######################### Читатели #######################\n",
    "if options.readers == True:\n",
    "    info('Смотрим читателей')\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    else:\n",
    "        error(\"Задайте целевого пользователя\")\n",
    "        exit(0)\n",
    "\n",
    "    #session = get_session(url_login)\n",
    "    \n",
    "    for user in users:\n",
    "        url = f\"{config.scheme}://{config.base_url}/lenta/readers/?user={user}\"\n",
    "\n",
    "        print(f\"{user}:\\n\")\n",
    "\n",
    "        while url != 0:\n",
    "            r = aget(session, url)\n",
    "            get_readers_one(r.text)\n",
    "            url = get_next_page2(r.text)\n",
    "    \n",
    "    #exit(session)\n",
    "##########################################################\n",
    "# Подарки\n",
    "# Форум\n",
    "# Почта\n",
    "#################### Лайки ###################\n",
    "if options.likes == True:\n",
    "    info('Список того, что понравилось')\n",
    "\n",
    "    #session = get_session(url_login)\n",
    "    url = f\"{config.scheme}://{config.base_url}/bookmarks/likes/\"\n",
    "\n",
    "    i = 1\n",
    "    while url != 0:\n",
    "        r = aget(session, url)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "  \n",
    "        t1 = 'div[class~=\"list_item\"]'\n",
    "        t2 = 'div[class~=\"content-item3\"]'\n",
    "        items = bs.select(f'div[id=\"main\"] :is({t1},{t2}) a[href]')\n",
    "\n",
    "        for item in items:\n",
    "            text = item.text\n",
    "            href = item.attrs['href']\n",
    "            print(f\"{i}: {text};{href}\")\n",
    "            i += 1\n",
    "\n",
    "        url = get_next_page2(r.text)\n",
    "\n",
    "    #exit(session)\n",
    "######################### История входов ######################\n",
    "if options.history_login == True:\n",
    "    info(\"Смотрим историю входов\")\n",
    "    \n",
    "    #session = get_session(url_login)\n",
    "    url = f'{config.scheme}://{config.base_url}/mysite/loghist/'\n",
    "\n",
    "    while url != 0:\n",
    "        r = aget(session, url)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        items = bs.select('div[class=\"content\"] div[class~=\"content-item3\"]')\n",
    "\n",
    "        for i, item in enumerate(items):\n",
    "            print(f\"{i+1}:\\n{item.text}\")\n",
    "\n",
    "        url = get_next_page2(r.text)\n",
    "\n",
    "    #exit(session)\n",
    "#############################################################\n",
    "if options.del_bookmarks == True:\n",
    "\n",
    "    url = f\"{config.scheme}://{config.base_url}/bookmarks/\"\n",
    "    info('Удаляем закладки')\n",
    "    delete_bookmarks2(session, url)\n",
    "#############################################################\n",
    "if options.del_comm == True:\n",
    "\n",
    "    url = f\"{config.scheme}://{config.base_url}/guestbook/\"\n",
    "    info('Комменты в гостевой')\n",
    "    delete_comment(session, url, 0)\n",
    "##############################################################\n",
    "if options.post == True:\n",
    "    info(\"Скачиваем всё из почты\")\n",
    "    \n",
    "    user = login\n",
    "    stor = config.base_url\n",
    "    info(f\"{stor}/{user}/\")\n",
    "\n",
    "    if user not in os.listdir(stor):\n",
    "        stor = f\"{stor}{os.sep}{user}\"\n",
    "        os.mkdir(stor)\n",
    "    else:\n",
    "        stor = f\"{stor}{os.sep}{user}\"\n",
    "    \n",
    "    if 'post' not in os.listdir(stor):\n",
    "        stor = f\"{stor}{os.sep}post\"\n",
    "        os.mkdir(stor)\n",
    "    else:\n",
    "        stor = f\"{stor}{os.sep}post\"\n",
    "\n",
    "    url_start = f\"{config.scheme}://{config.base_url}/mail/?List=3\"\n",
    "    \n",
    "    while url_start != 0:\n",
    "        r = aget(session, url_start)\n",
    "        text = r.text\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "        tt = bs.select('a[class~=\"mail__msg\"][href]')\n",
    "\n",
    "        for i, t in enumerate(tt):\n",
    "            info(f\"{i+1}: {t.attrs['href']}\")\n",
    "            url = t.attrs['href']\n",
    "            \n",
    "            download_one_elem(session, url, stor)\n",
    "\n",
    "        url_start = get_next_page2(text)\n",
    "\n",
    "##############################################################\n",
    "if options.diary == True:\n",
    "    info(\"Скачиваем всё из дневника\")\n",
    "    \n",
    "    users = []\n",
    "    if len(args) > 0:\n",
    "        users = args\n",
    "    else:\n",
    "        error(\"Задайте целевого пользователя\")\n",
    "        exit(0)\n",
    "    \n",
    "    for user in users:\n",
    "        #user = login\n",
    "        stor = config.base_url\n",
    "        info(f\"{stor}/{user}/diary\")\n",
    "\n",
    "        if user not in os.listdir(stor):\n",
    "            stor = f\"{stor}{os.sep}{user}\"\n",
    "            os.mkdir(stor)\n",
    "        else:\n",
    "            stor = f\"{stor}{os.sep}{user}\"\n",
    "\n",
    "        if 'diary' not in os.listdir(stor):\n",
    "            stor = f\"{stor}{os.sep}diary\"\n",
    "            os.mkdir(stor)\n",
    "        else:\n",
    "            stor = f\"{stor}{os.sep}diary\"\n",
    "\n",
    "        url = f\"{config.scheme}://{config.base_url}/diary/view/user/{user}/\"\n",
    "        #url = 'https://spcs.pro/bookmarks/index/'\n",
    "        i = 1\n",
    "        while url != 0:\n",
    "            r = aget(session, url)\n",
    "            bs = BeautifulSoup(r.text, 'html.parser')\n",
    "            sel2 = 'div[class~=\"stnd-block\"] a[href][class~=\"tdn\"]'\n",
    "            #sel2 = 'div[class~=\"wbg\"] a[href][class~=\"list-link\"]'\n",
    "            ttt = bs.select(sel2)\n",
    "            \n",
    "            for t in ttt:\n",
    "                info(f\"Страница {i}: {t.attrs['href']}\")\n",
    "                url_d = t.attrs['href']\n",
    "                ###\n",
    "                download_one_elem(session, url_d, stor)\n",
    "                i+=1\n",
    "\n",
    "            url = get_next_page(r.text)\n",
    "\n",
    "############################################################## \n",
    "if options.one_element is not None:\n",
    "    url = str(options.one_element)\n",
    "    stor = '.'\n",
    "    download_one_elem(session, url, stor)\n",
    "##############################################################\n",
    "if options.pic_top == True:\n",
    "    info('Собираем картинки с главной')\n",
    "\n",
    "    limit = None\n",
    "    if (len(args) > 0) and (str(args[0]).isnumeric()):\n",
    "        limit = int(args[0])\n",
    "        \n",
    "    #https://spcs.global/sz/foto-i-kartinki/\n",
    "    #https://spcs.global/sz/foto-i-kartinki/month/\n",
    "    #https://spcs.global/sz/foto-i-kartinki/all/\n",
    "\n",
    "    part = 'pic_top'\n",
    "    url_target = f\"{config.scheme}://{config.base_url}/sz/foto-i-kartinki/\"\n",
    "    session = get_session(url_target)\n",
    "    \n",
    "    info(url_target)\n",
    "\n",
    "    dt = time.strftime('%Y-%m-%d_%H-%M-%S_%z')\n",
    "    \n",
    "    if config.base_url not in os.listdir():\n",
    "        os.mkdir(config.base_url)\n",
    "    if f\"{part}_{dt}\" not in os.listdir(config.base_url):\n",
    "        os.mkdir(f\"{config.base_url}{os.sep}{part}_{dt}\")\n",
    "    stor = f\"{config.base_url}{os.sep}{part}_{dt}\"\n",
    "\n",
    "    coll(session, url_target, part, stor, limit)\n",
    "##############################################################\n",
    "# Сбрасываем статистику подключений\n",
    "exit(session)\n",
    "info(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-conflict",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-thursday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-geneva",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-treat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-respondent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-morgan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-plaza",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
